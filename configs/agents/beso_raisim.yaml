_target_: beso.agent.beso_agent.BesoAgent
_recursive_: false

defaults:
  - model: diffusion_transformer

optimization:
  _target_: torch.optim.AdamW
  lr: 1e-3
  betas: [0.9, 0.999]

# lr_scheduler:
#   _target_: torch.optim.lr_scheduler.CosineAnnealingLR
#   T_max: ${max_train_steps}

lr_scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  factor: 0.5
  patience: 10000

max_train_steps: ${max_train_steps}
eval_every_n_steps: ${eval_every_n_steps}
num_sampling_steps: ${n_timesteps}
sigma_data: ${sigma_data}
sigma_min: 0.005
sigma_max: 1
use_ema: ${use_ema}
decay: ${decay}
device: ${device}
update_ema_every_n_steps: ${update_ema_every_n_steps}

obs_dim: ${obs_dim}
pred_obs_dim: ${pred_obs_dim}
action_dim: ${action_dim}
T: ${T}
T_cond: ${T_cond}
T_action: ${T_action}
num_envs: ${env.num_envs}
sim_every_n_steps: ${sim_every_n_steps}
